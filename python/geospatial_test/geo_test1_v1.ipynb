{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import general modules\n",
    "import numpy as np\n",
    "import io, sys, time, math, os.path, unittest, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Todo: use sys commands to dynamically find in github folder\n",
    "github_folder='/Users/mrubashkin/greenspace/'\n",
    "file_location=github_folder+'raw_data/Dept_Interior_Data/'\n",
    "\n",
    "file_name='NRRS_reservations_byVisitorOriginZip_AllYears.csv'\n",
    "zip_origin_df=pd.read_csv(file_location+file_name)\n",
    "\n",
    "file_name='NRRS_reservations_byFacilityName_AllYears.csv'\n",
    "by_campground_df=pd.read_csv(file_location+file_name)\n",
    "\n",
    "file_name='PPL_reservationdata.csv' #2.2gb --> very large\n",
    "reservation_df=by_campground_df=pd.read_csv(file_location+file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load models (distance to park)\n",
    "github_folder='/Users/mrubashkin/greenspace/'\n",
    "file_location=github_folder+'raw_data/'\n",
    "file_name='ESRI_ZipCodes_wDistance2nearestFacility_km.txt'\n",
    "distance_to_park_df=pd.read_csv(file_location+file_name)\n",
    "#distance_to_park_df[['D2NF_km','ZIP_CODE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Census Data\n",
    "file_location=github_folder+'raw_data/'\n",
    "\n",
    "file_name='aggregate_income.csv'\n",
    "income_df=pd.read_csv(file_location+file_name)\n",
    "\n",
    "file_name='2010CensusPopulationData.csv'\n",
    "racial_info_df=pd.read_csv(file_location+file_name)\n",
    "\n",
    "#distance from zip code to the park\n",
    "file_name='ESRI_ZipCodes_wDistance2nearestFacility_km.txt'\n",
    "distance_to_park_df=pd.read_csv(file_location+file_name)\n",
    "distance_to_park_df[['D2NF_km','ZIP_CODE']]\n",
    "\n",
    "#health/disabilty\n",
    "file_name='disability.csv'\n",
    "disability_df=pd.read_csv(file_location+file_name)\n",
    "'''\n",
    "TODO: Rename these columns, the one 'total is a BAD idea\n",
    "'''\n",
    "\n",
    "file_name='education.csv'\n",
    "education_df=pd.read_csv(file_location+file_name)\n",
    "education_df.rename(columns={'zip code tabulation area': 'zip_code_tabulation_area'},inplace=True)\n",
    "education_df.rename(columns={'B06009_001E': 'Total_reported_education_per_zip'},inplace=True)\n",
    "education_df.rename(columns={'B06009_002E': 'Less_than_high_school_graduate'},inplace=True)\n",
    "education_df.rename(columns={'B06009_003E': 'High_school_graduate'},inplace=True)\n",
    "education_df.rename(columns={'B06009_004E': 'Some_college_or_associates_degree'},inplace=True)\n",
    "education_df.rename(columns={'B06009_005E': 'Bachelor_degree'},inplace=True)\n",
    "education_df.rename(columns={'B06009_006E': 'Graduate_or_professional_degree'},inplace=True)\n",
    "education_df=education_df[['zip_code_tabulation_area','Less_than_high_school_graduate','High_school_graduate'\n",
    "                ,'Some_college_or_associates_degree','Bachelor_degree','Graduate_or_professional_degree'\n",
    "                ,'Total_reported_education_per_zip']]\n",
    "#education_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop the duplicate columns and use to merge\n",
    "temp=reservation_df.drop_duplicates(subset = ' CustZip')\n",
    "temp=temp[[' CustState',' CustCountry',' CustZip']]\n",
    "temp[' CustZip']=pd.to_numeric(temp[' CustZip'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#join the dataframes\n",
    "aggregate_df= pd.merge(zip_origin_df, racial_info_df, left_on = 'visitor_zip', right_on = 'Zip')\n",
    "aggregate_df= pd.merge(aggregate_df,income_df,left_on='visitor_zip',right_on='zip code tabulation area')\n",
    "#move the line below to higher up\n",
    "aggregate_df.rename(columns={'Annual Aggregate Family Income': 'Annual_Aggregate_Family_Income'},inplace=True)\n",
    "aggregate_df= pd.merge(aggregate_df,temp,left_on = 'visitor_zip', right_on = ' CustZip')\n",
    "aggregate_df= pd.merge(aggregate_df,education_df,left_on='visitor_zip',right_on='zip_code_tabulation_area')\n",
    "aggregate_df= pd.merge(aggregate_df,distance_to_park_df,left_on='visitor_zip',right_on='ZIP_CODE')\n",
    "aggregate_df= pd.merge(aggregate_df,disability_df, left_on='visitor_zip',right_on='zipcode')\n",
    "#aggregate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'visitor_zip', u'visitorzip_lat', u'visitorzip_lon', u'qpartysize25',\n",
      "       u'qpartysize50', u'qpartysize75', u'qleadt25', u'qleadt50', u'qleadt75',\n",
      "       u'qdur25', u'qdur50', u'qdur75', u'qdist25', u'qdist50', u'qdist75',\n",
      "       u'res_count', u'sum_dur', u'sum_persnight', u'Zip', u'Population',\n",
      "       u'PopulationMale', u'PopulationFemale', u'MedianAge', u'MedianAgeMale',\n",
      "       u'MedianAgeFemale', u'PopulationRaceWhite', u'PopulationRaceBlack',\n",
      "       u'PopulationAmerindian', u'PopulationRaceAsian',\n",
      "       u'PopulationRacePacific', u'PopulationRaceOther',\n",
      "       u'PopulationRaceMulti', u'PopulationRaceLatino', u'Households',\n",
      "       u'HusbandWifeHouseholds', u'SingleFatherHousehold',\n",
      "       u'SingleMotherHousehold', u'NonFamilyHouseholds', u'HouseHolder15to24',\n",
      "       u'HouseHolder25to34', u'HouseHolder35to44', u'HouseHolder45to54',\n",
      "       u'HouseHolder55to59', u'HouseHolder60to64', u'HouseHolder65to74',\n",
      "       u'HouseHolder75to84', u'HouseHolder85over', u'HouseholdsWith60Plus',\n",
      "       u'HouseholdsWith75Plus', u'Households2Person'],\n",
      "      dtype='object')\n",
      "Index([u'Households3Person', u'Households4Person', u'Households5Person',\n",
      "       u'Households6Person', u'Households7PlusPerson', u'Unnamed: 0_x',\n",
      "       u'Annual_Aggregate_Family_Income', u'zip code tabulation area',\n",
      "       u' CustState', u' CustCountry', u' CustZip',\n",
      "       u'zip_code_tabulation_area', u'Less_than_high_school_graduate',\n",
      "       u'High_school_graduate', u'Some_college_or_associates_degree',\n",
      "       u'Bachelor_degree', u'Graduate_or_professional_degree',\n",
      "       u'Total_reported_education_per_zip', u'FID', u'FID_1', u'OBJECTID',\n",
      "       u'ZIP_CODE', u'PO_NAME', u'STATE', u'ZIP_TYPE', u'POPULATION',\n",
      "       u'POP_SQMI', u'SQMI', u'FID_2', u'Park', u'Cnt_Park', u'First_Agen',\n",
      "       u'First_Site', u'Last_SiteT', u'First_FacZ', u'First_Park',\n",
      "       u'Min_ParkLo', u'Max_ParkLo', u'ParkLat', u'Distance', u'D2NF_km',\n",
      "       u'Unnamed: 0_y', u'total', u'disabled'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print aggregate_df.columns[0:50]\n",
    "print aggregate_df.columns[50:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'USA'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename columns without spaces\n",
    "aggregate_df.rename(columns={' CustZip': 'CustZip'},inplace=True)\n",
    "aggregate_df.rename(columns={' CustState': 'CustState'},inplace=True)\n",
    "aggregate_df.rename(columns={' CustCountry': 'Custcountry'},inplace=True)\n",
    "aggregate_df.iloc[0]['Custcountry']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the utilization_factors into the dataframe\n",
    "aggregate_df['util_unique'] = pd.Series(\n",
    "    (aggregate_df.sum_dur / aggregate_df.Population))\n",
    "aggregate_df['util_days']= pd.Series(\n",
    "    (aggregate_df.sum_persnight  / aggregate_df.Population))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This 0.000754 should equal that 0.000754\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TODO\n",
    "make a unittest to make sure this is joined correctly\n",
    "'''\n",
    "print 'This %f should equal that %f'%\\\n",
    "    (float(aggregate_df.iloc[[0]]['sum_dur']\\\n",
    "    /float(aggregate_df.iloc[[0]]['Population'])),\\\n",
    "     float(aggregate_df.iloc[[0]]['util_unique']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the male/female breakdowns per visit per zip code\n",
    "#using unique visits for the rest of these breakdowns!! (i.e. sum_dur)\n",
    "aggregate_df['visits_female'] = pd.Series(\n",
    "    ((aggregate_df.PopulationFemale / aggregate_df.Population)*aggregate_df.sum_dur))\n",
    "aggregate_df['visits_male'] = pd.Series(\n",
    "    ((aggregate_df.PopulationFemale / aggregate_df.Population)*aggregate_df.sum_dur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This 7.156058 should equal that 7.156058\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TODO\n",
    "make a unittest to make sure this is joined correctly\n",
    "'''\n",
    "print 'This %f should equal that %f'%\\\n",
    "    (float(aggregate_df.iloc[[0]]['PopulationFemale']\\\n",
    "    /float(aggregate_df.iloc[[0]]['Population']))\\\n",
    "    *float(aggregate_df.iloc[[0]]['sum_dur']),\\\n",
    "     float(aggregate_df.iloc[[0]]['visits_female']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the race breakdown per visit per zip code\n",
    "aggregate_df['visits_RaceWhite'] = pd.Series(\n",
    "    (aggregate_df.PopulationRaceWhite * aggregate_df.sum_dur))\n",
    "aggregate_df['visits_RaceBlack'] = pd.Series(\n",
    "    (aggregate_df.PopulationRaceBlack * aggregate_df.sum_dur))\n",
    "aggregate_df['visits_Amerindian'] = pd.Series(\n",
    "    (aggregate_df.PopulationAmerindian * aggregate_df.sum_dur))\n",
    "aggregate_df['visits_RacePacific'] = pd.Series(\n",
    "    (aggregate_df.PopulationRacePacific * aggregate_df.sum_dur))\n",
    "aggregate_df['visits_RaceLatino'] = pd.Series(\n",
    "    (aggregate_df.PopulationRaceLatino * aggregate_df.sum_dur))\n",
    "aggregate_df['visits_RaceMulti'] = pd.Series(\n",
    "    (aggregate_df.PopulationRaceMulti * aggregate_df.sum_dur))\n",
    "aggregate_df['visits_RaceOther'] = pd.Series(\n",
    "    (aggregate_df.PopulationRaceOther * aggregate_df.sum_dur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This 0.060312 should equal that 0.060312\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TODO\n",
    "make a unittest to make sure this is joined correctly\n",
    "'''\n",
    "print 'This %f should equal that %f'%\\\n",
    "    (float(aggregate_df.iloc[[0]]['PopulationRaceWhite']\\\n",
    "    *float(aggregate_df.iloc[[0]]['sum_dur'])),\\\n",
    "     float(aggregate_df.iloc[[0]]['visits_RaceWhite']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#scale the annual family aggregate income (which is per zip code)\n",
    "#to individual families\n",
    "aggregate_df['per_family_annual_income'] = pd.Series(\n",
    "    (aggregate_df.Annual_Aggregate_Family_Income / aggregate_df.Households))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This 16366.160920 should equal that 16366.160920\n"
     ]
    }
   ],
   "source": [
    "print 'This %f should equal that %f'%\\\n",
    "    (float(aggregate_df.iloc[[0]]['Annual_Aggregate_Family_Income']\\\n",
    "    /float(aggregate_df.iloc[[0]]['Households'])),\\\n",
    "     float(aggregate_df.iloc[[0]]['per_family_annual_income']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get percent of people who are high school educated\n",
    "aggregate_df['non_hs_educated'] = pd.Series(\n",
    "    (aggregate_df.Less_than_high_school_graduate / aggregate_df.Total_reported_education_per_zip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This 0.109489 should equal that 0.109489\n"
     ]
    }
   ],
   "source": [
    "print 'This %f should equal that %f'%\\\n",
    "    (float(aggregate_df.iloc[[-1]]['Less_than_high_school_graduate']\\\n",
    "    /float(aggregate_df.iloc[[-1]]['Total_reported_education_per_zip'])),\\\n",
    "     float(aggregate_df.iloc[[-1]]['non_hs_educated']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get percent of people who are high school educated\n",
    "aggregate_df['disabled_percent'] = pd.Series(\n",
    "    (aggregate_df.disabled / aggregate_df.total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This 0.257353 should equal that 0.257353\n"
     ]
    }
   ],
   "source": [
    "print 'This %f should equal that %f'%\\\n",
    "    (float(aggregate_df.iloc[[-1]]['disabled']\\\n",
    "    /float(aggregate_df.iloc[[-1]]['total'])),\\\n",
    "     float(aggregate_df.iloc[[-1]]['disabled_percent']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trim data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustZip                          4460\n",
       "CustState                          ME\n",
       "Custcountry                       USA\n",
       "visitorzip_lat                45.6494\n",
       "visitorzip_lon                -68.579\n",
       "per_family_annual_income      38083.6\n",
       "non_hs_educated              0.122984\n",
       "PopulationRaceWhite          0.987315\n",
       "Dist_to_park                  140.192\n",
       "util_days                   0.0190275\n",
       "disabled_percent             0.212673\n",
       "MedianAge                        48.2\n",
       "Name: 1092, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the data to send to Cartos DB and use for the graphing\n",
    "regression_df=aggregate_df[[\n",
    "        'CustZip',\n",
    "        'CustState',\n",
    "        'Custcountry',\n",
    "        'visitorzip_lat',\n",
    "        'visitorzip_lon',\n",
    "        'per_family_annual_income',\n",
    "        'non_hs_educated',\n",
    "        'PopulationRaceWhite',\n",
    "        'D2NF_km',\n",
    "        'util_days',\n",
    "        'disabled_percent',\n",
    "        'MedianAge',\n",
    "        ]]\n",
    "#remove inf and NaN\n",
    "regression_df=regression_df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "#rename the distance column\n",
    "regression_df.rename(columns={'D2NF_km': 'Dist_to_park'},inplace=True)\n",
    "#save the max values    \n",
    "income_max=regression_df['per_family_annual_income'].max()\n",
    "dist_to_park_max=regression_df['Dist_to_park'].max()\n",
    "#print random entry\n",
    "regression_df.iloc[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for Mythin\n",
    "regression_df['log_util_days'] = pd.Series(\n",
    "    (np.log(regression_df.util_days)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the trimmed datframe to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save the dataframe to a csv\n",
    "file_location=github_folder + 'processed_data/'\n",
    "file_name='test9_with_log_util_days.csv'\n",
    "regression_df.to_csv(file_location+file_name, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the columns to 0 to 1 for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scale columns to 0-->1\n",
    "regression_df[['per_family_annual_income']]=\\\n",
    "regression_df[['per_family_annual_income']].divide(\\\n",
    "    regression_df['per_family_annual_income'].max())\n",
    "regression_df[['Dist_to_park']]=\\\n",
    "regression_df[['Dist_to_park']].divide(\\\n",
    "    regression_df['Dist_to_park'].max())\n",
    "regression_df[['MedianAge']]=\\\n",
    "regression_df[['MedianAge']].divide(\\\n",
    "    regression_df['MedianAge'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.245\n",
      "Model:                            OLS   Adj. R-squared:                  0.245\n",
      "Method:                 Least Squares   F-statistic:                     1605.\n",
      "Date:                Sun, 24 Apr 2016   Prob (F-statistic):               0.00\n",
      "Time:                        00:33:11   Log-Likelihood:                -57050.\n",
      "No. Observations:               29698   AIC:                         1.141e+05\n",
      "Df Residuals:                   29692   BIC:                         1.142e+05\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.1176      0.114      1.031      0.303        -0.106     0.341\n",
      "x2             1.7278      0.173      9.962      0.000         1.388     2.068\n",
      "x3            -8.8589      0.241    -36.701      0.000        -9.332    -8.386\n",
      "x4             1.0373      0.050     20.901      0.000         0.940     1.135\n",
      "x5             0.8479      0.109      7.767      0.000         0.634     1.062\n",
      "x6            -0.4133      0.222     -1.864      0.062        -0.848     0.021\n",
      "const               0          0        nan        nan             0         0\n",
      "==============================================================================\n",
      "Omnibus:                    55153.957   Durbin-Watson:                   1.434\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        237670208.785\n",
      "Skew:                          13.608   Prob(JB):                         0.00\n",
      "Kurtosis:                     440.412   Cond. No.                          inf\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is      0. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "#remove potential ouliers\n",
    "min_visitation_value=.01\n",
    "regression_df_editted = regression_df[regression_df.util_days > min_visitation_value]\n",
    "\n",
    "y=regression_df_editted['util_days'].tolist()\n",
    "\n",
    "x=[regression_df_editted['per_family_annual_income'].tolist(),\n",
    "   regression_df_editted['non_hs_educated'].tolist(),\n",
    "   regression_df_editted['PopulationRaceWhite'].tolist(),\n",
    "   regression_df_editted['Dist_to_park'].tolist(),\n",
    "   regression_df_editted['disabled_percent'].tolist(),\n",
    "   regression_df_editted['MedianAge'].tolist()\n",
    "   ]\n",
    "\n",
    "#calculate the y-intercept guess\n",
    "y_intercept_guess=regression_df_editted['util_days'].median()\n",
    "y_intercept_guess=0\n",
    "\n",
    "def reg_m(y, x, y_intercept_guess):\n",
    "    y_intercepts = np.empty(len(x[0]))\n",
    "    y_intercepts.fill(y_intercept_guess)\n",
    "    X = sm.add_constant(np.column_stack((x[0], y_intercepts)))\n",
    "    for ele in x[1:]:\n",
    "        X = sm.add_constant(np.column_stack((ele, X)))\n",
    "    results = sm.OLS(y, X).fit()\n",
    "    return results\n",
    "\n",
    "reg_m(y,x,y_intercept_guess)\n",
    "print reg_m(y, x,y_intercept_guess).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.010008094782544705, 0.081082138476504681, 0.19477498600097548, 0.44295962588448456, 1.1330040056305426, 84.264516129032259]\n",
      "[0.07823960880195599, 0.1520534269682261, 0.15652687536916715, 0.22684142262270462, 0.087885985748218529, 0.097165991902834009, 0.27015793848711556, 0.060583941605839416, 2.5052950075642966, 0.13795928928756254]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16535, 3823, 25356, 14174, 27982, 13019, 12648, 10047, 25096, 18701]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def training_sample_index(training_size):\n",
    "    import random\n",
    "    #Create random sampling array\n",
    "    #cannot be larger than the availble data\n",
    "    r_df_length=len(regression_df_editted['util_days'])\n",
    "    total_samples=int(training_size*r_df_length)\n",
    "    training_sample=random.sample(range(0, r_df_length), total_samples)\n",
    "    #print training_sample[0:10]\n",
    "    return training_sample\n",
    "\n",
    "def build_training_set(training_sample,df_as_list):\n",
    "    #open df as list and store temporarily\n",
    "    df_list=regression_df_editted['util_days'].tolist()\n",
    "    df_output=[]\n",
    "    for i in range(0,len(training_sample)):\n",
    "        df_output.append(df_list[training_sample[i]])\n",
    "        '''\n",
    "        TODO: Create unittest confirming here that we are returning the\n",
    "        correct mixed index values\n",
    "        '''\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bucket_and_prob_creator(buckets):\n",
    "    # Convert util_days (average person visits to park over 7 years) to ranking 1-5(low-high)\n",
    "    '''\n",
    "    TODO: make this a function that does not rely on global variables\n",
    "    NOT CURRENTLY WORKING\n",
    "    '''\n",
    "    a = regression_df_editted['util_days'].tolist()\n",
    "    p=[]\n",
    "    for i in range(0,len(buckets)):\n",
    "        p.append(np.percentile(a, values[i]))\n",
    "    return p\n",
    "\n",
    "def assign_class_to_value(input_value,buckets,p,output_classes):\n",
    "    for i in range(1,len(buckets)):\n",
    "        if i==len(buckets):\n",
    "            if input_value>p[i]:\n",
    "                return output_classes[i]\n",
    "        if input_value<p[i]:\n",
    "            return output_classes[i-1]\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create training sample index and build training set\n",
    "training_sample=training_sample_index(training_size=0.1)\n",
    "r_df_lists={}\n",
    "#create a list index\n",
    "list_index=['util_days','per_family_annual_income','non_hs_educated',\n",
    "           'PopulationRaceWhite','Dist_to_park','disabled_percent','MedianAge']\n",
    "#then iterate through the other data\n",
    "for i in range(0,len(list_index)):\n",
    "    r_df_lists[list_index[i]]=\\\n",
    "        build_training_set(training_sample,regression_df_editted[list_index[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#assign classes for decision tree to the util_days value range\n",
    "buckets=[0,20,40,60,80,100]\n",
    "output_classes=[0,1,2,3,4]\n",
    "p=bucket_and_prob_creator(buckets)\n",
    " \n",
    "for i in range(0,len(r_df_lists['util_days'])):\n",
    "    r_df_lists['util_days'][i]= \\\n",
    "        assign_class_to_value(r_df_lists['util_days'][i],buckets,p,output_classes)\n",
    "'''\n",
    "TODO Write a test to make sure these are all integers and members of the output_classes array\n",
    "#print r_df_lists['util_days'][0:30]\n",
    "'''\n",
    "\n",
    "#convert all lists in r_df_lists dictionary to numpy array\n",
    "keys=r_df_lists.keys()\n",
    "for key in keys:\n",
    "    r_df_lists[key]=np.array(r_df_lists[key])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "iris = load_iris()\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(iris.data, iris.target)\n",
    "#print 'data /n', iris.data\n",
    "#print 'target /n', iris.target\n",
    "\n",
    "y=r_df_lists['util_days']\n",
    "\n",
    "#convert the x into the appropriate format\n",
    "x=[]\n",
    "for i in range(0,len(r_df_lists[keys[0]])): #start at 1 to skip util_days\n",
    "    temp=[]\n",
    "    for key in keys:\n",
    "        temp.append(r_df_lists[key][i])\n",
    "    x.append(temp)\n",
    "    \n",
    "'''     \n",
    "x=[r_df_lists['per_family_annual_income'],\n",
    "  r_df_lists['non_hs_educated'],\n",
    "  r_df_lists['PopulationRaceWhite'],\n",
    "  r_df_lists['Dist_to_park'],\n",
    "  r_df_lists['disabled_percent'],\n",
    "  r_df_lists['MedianAge']]\n",
    "'''\n",
    "\n",
    "print len(x),len(y)\n",
    "print x[1][0:5]\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(x, y)\n",
    "#print 'data /n', x\n",
    "#print 'target /n', y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print keys\n",
    "print (keys[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=regression_df_editted['util_days'].tolist()\n",
    "\n",
    "x=[regression_df_editted['per_family_annual_income'].tolist(),\n",
    "   regression_df_editted['non_hs_educated'].tolist(),\n",
    "   regression_df_editted['PopulationRaceWhite'].tolist(),\n",
    "   regression_df_editted['Dist_to_park'].tolist(),\n",
    "   regression_df_editted['disabled_percent'].tolist(),\n",
    "   regression_df_editted['MedianAge'].tolist()\n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO\n",
    "with open(\"iris.dot\", 'w') as f:\n",
    "    f = tree.export_graphviz(clf, out_file=f)\n",
    "    \n",
    "import os\n",
    "os.unlink('iris.dot')\n",
    "\n",
    "from sklearn.externals.six import StringIO  \n",
    "import pydot \n",
    "dot_data = StringIO() \n",
    "tree.export_graphviz(clf, out_file=dot_data) \n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue()) \n",
    "graph.write_pdf(\"iris.pdf\") \n",
    "\n",
    "from IPython.display import Image  \n",
    "dot_data = StringIO()  \n",
    "tree.export_graphviz(clf, out_file=dot_data,  \n",
    "                     feature_names=iris.feature_names,  \n",
    "                     class_names=iris.target_names,  \n",
    "                     filled=True, rounded=True,  \n",
    "                     special_characters=True)  \n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Parameters\n",
    "n_classes = 3\n",
    "plot_colors = \"bry\"\n",
    "plot_step = 0.02\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "\n",
    "for pairidx, pair in enumerate([[0, 1], [0, 2], [0, 3],\n",
    "                                [1, 2], [1, 3], [2, 3]]):\n",
    "    # We only take the two corresponding features\n",
    "    X = iris.data[:, pair]\n",
    "    y = iris.target\n",
    "\n",
    "    # Shuffle\n",
    "    idx = np.arange(X.shape[0])\n",
    "    np.random.seed(13)\n",
    "    np.random.shuffle(idx)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "\n",
    "    # Standardize\n",
    "    mean = X.mean(axis=0)\n",
    "    std = X.std(axis=0)\n",
    "    X = (X - mean) / std\n",
    "\n",
    "    # Train\n",
    "    clf = DecisionTreeClassifier().fit(X, y)\n",
    "\n",
    "    # Plot the decision boundary\n",
    "    plt.subplot(2, 3, pairidx + 1)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "    plt.xlabel(iris.feature_names[pair[0]])\n",
    "    plt.ylabel(iris.feature_names[pair[1]])\n",
    "    plt.axis(\"tight\")\n",
    "\n",
    "    # Plot the training points\n",
    "    for i, color in zip(range(n_classes), plot_colors):\n",
    "        idx = np.where(y == i)\n",
    "        plt.scatter(X[idx, 0], X[idx, 1], c=color, label=iris.target_names[i],\n",
    "                    cmap=plt.cm.Paired)\n",
    "\n",
    "    plt.axis(\"tight\")\n",
    "\n",
    "plt.suptitle(\"Decision surface of a decision tree using paired features\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.semilogy(regression_df['PopulationRaceWhite'],regression_df['util_days'],'ro',\\\n",
    "             regression_df['per_family_annual_income'],regression_df['util_days'],'bo',\\\n",
    "             regression_df['Dist_to_park'],regression_df['util_days'],'go',\\\n",
    "             regression_df['non_hs_educated'],regression_df['util_days'],'ko',\\\n",
    "             regression_df['disabled_percent'],regression_df['util_days'],'co',markersize = 2\n",
    "             )\n",
    "\n",
    "plt.xlabel('Percent of zip code white',size=14)\n",
    "plt.ylabel('Visits to park per person from 2007-2015', size=13)\n",
    "plt.title('Park visits by % of population identifying as White \\n by zipcode', size=13)\n",
    "plt.legend(loc='upper right',prop={'size':12})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.semilogy(regression_df['per_family_annual_income'],\\\n",
    "             regression_df['util_days'],'ro',markersize = 4)\n",
    "plt.xlabel('Family Income',size=14)\n",
    "plt.ylabel('Visits to park per person from 2007-2015', size=13)\n",
    "plt.title('Park visits by % of population identifying as White \\n by zipcode', size=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.semilogy(regression_df['Dist_to_park'],\\\n",
    "             regression_df['util_days'],'ro',markersize = 4)\n",
    "plt.xlabel('Distance_to_park',size=14)\n",
    "plt.ylabel('Visits to park per person from 2007-2015', size=13)\n",
    "plt.title('Park visits by distance to park', size=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.semilogy(regression_df['non_hs_educated'],\\\n",
    "             regression_df['util_days'],'ro',markersize = 4)\n",
    "plt.xlabel('Distance_to_park',size=14)\n",
    "plt.ylabel('Visits to park per person from 2007-2015', size=13)\n",
    "plt.title('Education Status (1=not high school educated) \\n per zipcode', size=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
